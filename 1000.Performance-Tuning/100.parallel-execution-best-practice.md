# 启用并行执行的最佳实践

并行执行是指多个线程同时处理同一子任务，以提高整体查询任务的执行效率。

启用并行执行的优势：

- **性能提升**：并行处理显著降低查询响应时间。
- **资源利用**：更有效地利用系统的多核 CPU 和多节点架构。
- **扩展性**：随着硬件资源的增加，处理能力可以线性提升。

## 并行执行的使用场景

并行执行适用于以下主要场景：

1. **并行查询**：
   - 当查询的表数据量较大时，数据扫描、排序、聚合和连接的开销会很高。通过并行处理，多个线程可以共同完成这些操作，显著降低查询耗时。

2. **并行 DML**：
   - 在执行 DML 操作（如 `insert`、`update`、`delete` 和 `merge into`）时，可通过并行执行提升性能。不过，需要在语句中添加 HINT `/*+ enable_parallel_dml */`，否则只有查询部分会并行执行，而 DML 部分将继续以串行方式进行。

3. **并行建索引**：
   - 对于大表建索引耗时长的问题，可以通过并行建索引来提高效率，示例语法如下：
   ```sql
   create /*+ parallel(32) */ index idx on big_table(c1);
   ```

## 注意事项与说明

- **资源竞争**：并行执行可能引发资源竞争，因此必须合理[设置并行执行并行度](https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001052988)。
- **事务一致性**：确保并行执行不会损害数据库的事务一致性。
- **监控与调优**：定期[监控](https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001050566)并行执行的性能，并根据需要进行调优。

## 如何开启并行执行

在 OceanBase 数据库中，SQL 默认以串行方式执行。用户可以通过以下几种方式启用并行执行：

### 方式一：通过 HINT 指定并行度

使用 HINT `/*+ parallel(degree) */` 可以为整个 SQL 语句指定统一的并行度，这是最常见的方法。并行度应根据租户配置和查询的数据量进行合理设置。可以使用 EXPLAIN 计划中的 DOP（Degree of Parallelism）查看每个子计划的并行度。

需要注意的是，在某些场景下，为不同子计划设置不同的并行度会更为合适。例如，如果 t1 表有一千万行而 t2 表只有十万行，为它们设定相同的并行度显然不太合理。此时，可以使用 HINT `/*+ parallel(table degree) */` 为每张表单独设置并行度。

例如：

```sql
select /*+ parallel(t2 2) parallel(t1 32) */ * from t1, t2 where t1.c1 = t2.c1;
+--------------------------------------------------------------------------------------------------------------------------+
| Query Plan                                                                                                               |
+--------------------------------------------------------------------------------------------------------------------------+
| =====================================================================                                                    |
| |ID|OPERATOR                         |NAME    |EST.ROWS|EST.TIME(us)|                                                    |
| ---------------------------------------------------------------------                                                    |
| |0 |PX COORDINATOR                   |        |11606039|5007604     |                                                    |
| |1 |└─EXCHANGE OUT DISTR             |:EX10002|11606039|587973      |                                                    |
| |2 |  └─HASH JOIN                    |        |11606039|278199      |                                                    |
| |3 |    ├─EXCHANGE IN DISTR          |        |200000  |49117       |                                                    |
| |4 |    │ └─EXCHANGE OUT DISTR (HASH)|:EX10000|200000  |47919       |                                                    |
| |5 |    │   └─PX BLOCK ITERATOR      |        |200000  |5081        |                                                    |
| |6 |    │     └─TABLE FULL SCAN      |t2      |200000  |5081        |                                                    |
| |7 |    └─EXCHANGE IN DISTR          |        |9984327 |201525      |                                                    |
| |8 |      └─EXCHANGE OUT DISTR (HASH)|:EX10001|9984327 |141704      |                                                    |
| |9 |        └─PX BLOCK ITERATOR      |        |9984327 |8047        |                                                    |
| |10|          └─TABLE FULL SCAN      |t1      |9984327 |8047        |                                                    |
| =====================================================================                                                    |
| Outputs & filters:                                                                                                       |
| -------------------------------------                                                                                    |
|   0 - output([INTERNAL_FUNCTION(t1.c1(0x7f007e422df0), t2.c1(0x7f007e423120))(0x7f007e5375e0)]), filter(nil), rowset=256 |
|   1 - output([INTERNAL_FUNCTION(t1.c1(0x7f007e422df0), t2.c1(0x7f007e423120))(0x7f007e5375e0)]), filter(nil), rowset=256 |
|       dop=32                                                                                                             |
|   2 - output([t1.c1(0x7f007e422df0)], [t2.c1(0x7f007e423120)]), filter(nil), rowset=256                                  |
|       equal_conds([t1.c1(0x7f007e422df0) = t2.c1(0x7f007e423120)(0x7f007e422640)]), other_conds(nil)                     |
|   3 - output([t2.c1(0x7f007e423120)]), filter(nil), rowset=256                                                           |
|   4 - output([t2.c1(0x7f007e423120)]), filter(nil), rowset=256                                                           |
|       (#keys=1, [t2.c1(0x7f007e423120)]), dop=2                                                                          |
|   5 - output([t2.c1(0x7f007e423120)]), filter(nil), rowset=256                                                           |
|   6 - output([t2.c1(0x7f007e423120)]), filter(nil), rowset=256                                                           |
|       access([t2.c1(0x7f007e423120)]), partitions(p0)                                                                    |
|       is_index_back=false, is_global_index=false,                                                                        |
|       range_key([t2.__pk_increment(0x7f007e423e20)]), range(MIN ; MAX)always true                                        |
|   7 - output([t1.c1(0x7f007e422df0)]), filter(nil), rowset=256                                                           |
|   8 - output([t1.c1(0x7f007e422df0)]), filter(nil), rowset=256                                                           |
|       (#keys=1, [t1.c1(0x7f007e422df0)]), dop=32                                                                         |
|   9 - output([t1.c1(0x7f007e422df0)]), filter(nil), rowset=256                                                           |
|  10 - output([t1.c1(0x7f007e422df0)]), filter(nil), rowset=256                                                           |
|       access([t1.c1(0x7f007e422df0)]), partitions(p0)                                                                    |
|       is_index_back=false, is_global_index=false,                                                                        |
|       range_key([t1.__pk_increment(0x7f007e423af0)]), range(MIN ; MAX)always true                                        |
```

### 方式二：建表时设定表级并行度

   在创建表时，可以使用如下语法设置表级并行度：

   ```sql
   create table big_table(c1 int) parallel = 32;
   ```

   但是，在实际应用中，建表时指定并行度的频率较低，因为通常不希望每条查询都使用并行查询。仅在表的数据量极大且查询 SQL 中过滤条件不足以精确控制的情况下，才会考虑使用建表时的并行度设置。

### 方式三：Auto DOP 功能

   为了解决使用 HINT 或建表时设置并行度可能带来的不便，OceanBase 数据库在 V4.2.1 版本推出了 Auto DOP 功能。用户可以通过 HINT `/*+ parallel(auto) */` 或设置系统变量启用 Auto DOP。启用后，数据库会根据租户配置和表的数据量自动计算合适的并行度，这样既省去了手动设置并行度的麻烦，又避免了统一并行度可能引起的不合理情况。

   启用和禁用 Auto DOP 的相关命令如下：

   ```sql
   /* 在 GLOBAL 级别启用 Auto DOP */
   SET global parallel_degree_policy = AUTO;

   /* 在 SESSION 级别启用 Auto DOP */
   SET parallel_degree_policy = AUTO;

   /* 在 GLOBAL 级别禁止 Auto DOP */
   SET global parallel_degree_policy = MANUAL;

   /* 在 SESSION 级别禁止 Auto DOP */
   SET parallel_degree_policy = MANUAL;
   ```

## 设置并行参数

开启并行执行以后，您可以设置并行参数，针对数据处理或复杂计算的应用，提升性能，使得计算任务能够更高效地完成。

与并行执行相关的参数主要包括 `parallel_degree_policy` 和 `parallel_servers_target`。

- **parallel_degree_policy**：控制 Auto DOP 的开关，如前文所述。
- **parallel_servers_target**：表示租户在每个节点上可申请的并行执行线程数量，设置方式为：

  ```sql
  set global parallel_servers_target = N;
  ```

  这里的 N 值不能超过租户的 `MIN_CPU * 10`，通常建议设置为 `MIN_CPU * 5`。如果设置过高且并行执行流量大，可能会导致 CPU 资源耗尽。

在执行并行计划前，数据库会预估该计划在每个节点所占用的并行执行线程数量。如果每个节点上有足够的可用线程，该计划将正常执行；否则，将被放入重试队列，等待其他 SQL 执行完毕后释放线程。

## 并行执行的性能

并行执行并不是在所有情况下都能提升性能。在某些情况下，比如数据量较小或框架开销超过执行任务本身的开销时，开启并行执行可能会降低性能。用户可以使用 `gv$sql_plan_monitor` 视图分析并行执行性能问题。

`gv$sql_plan_monitor` 视图展示了计划执行过程中每个线程的关键信息，包括：

| 字段                   | 含义                   |
|------------------------|------------------------|
| TRACE_ID               | 追踪 ID                |
| PLAN_LINE_ID           | 算子 ID                |
| OUTPUT_ROWS            | 输出行数               |
| PROCESS_NAME           | 执行线程 ID           |
| FIRST_REFRESH_TIME     | 该线程开始执行时间     |
| LAST_REFRESH_TIME      | 该线程结束执行时间     |
| DB_TIME                | 在本算子上消耗的实际 CPU 时间 |

通常，用户可以通过 `trace_id` 过滤出指定 SQL 的执行记录，并按 `PLAN_LINE_ID` 进行聚合，以观察每个算子的指标。可以使用如下 SQL 查询各算子的并行度、输出行数、总 CPU 开销、开始时间和结束时间：

```sql
select plan_line_id, count(1) threads, sum(output_rows) rows, sum(db_time) cost,
  min(first_refresh_time) open_time, max(last_refresh_time) close_time
from gv$sql_plan_monitor where trace_id = 'xxx' group by plan_line_id;
```

## 相关文档

了解更多有关并行执行的概念、工作线程、问题诊断、分类与优化等信息，参见[并行执行](https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001050806)。

了解并行开启方式机器优先级，参见[并行开启方式及优先级](https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001050811)。

了解 OceanBase 数据库优化器的并行度 DOP，参见[Auto DOP](https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001050813)。

了解通过并行查询参数进行调优，参见[并行查询的参数调优](https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000001050817)。
