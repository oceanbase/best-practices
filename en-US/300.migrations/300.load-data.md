# Best practice for importing data files to OceanBase Database

This topic explains how to export files from the source database and import them to OceanBase Database. It also covers performance optimization techniques and includes an example.

## Export files from a database

You can export files from a database in the following ways:

1. Tools provided by the database.
2. Third-party tools. You can use various database management tools, such as DBeaver, SQLyog, and Navicat, to export data to files in different formats including CSV, EXCEL, and SQL.
3. Write a program to export data.

To export files from an Oracle database, you can use a database development tool such as Navicat or SQL Developer, or use SQL*Plus alone.

To export files from a MySQL database, you can use a database development tool such as Navicat or DBeaver, or use the export tool mysqldump. To export files from OceanBase Database, you can use obdumper.

Do not export files in a large size such as 100 GB or more. If the data export tool you are using cannot export data by file blocks, you can use a tool to split a large file into blocks.

## Import data to OceanBase Database

Run the following command to import data to OceanBase Database by using obloader:

```bash
$./obloader -h xx.x.x.x -P 2883 -u test@mysql#cluster_a -p ****** -D USERA --csv --table <table_name> --file-regular-expression '.*.csv' /output
```

For more information, see [Quick start](https://en.oceanbase.com/docs/common-oceanbase-dumper-loader-10000000001417511).

## Performance tuning

You can take the following measures to improve the import performance by considering both obloader and OceanBase Database parameters:

- Improve the parsing performance

    obloader cannot split binary files, namely, ORC and Parquet files. Therefore, you cannot improve the overall parsing performance by adjusting the concurrency. You can manually split large files into smaller blocks to improve the parsing performance.

- Improve the concurrency

    You can specify the `--thread` and `--rw` options to improve the concurrency, namely, the number of files processed at the same time. If the CPU utilization remains high, the CPU processing capacity of the client has reached a bottleneck. You can upgrade the specifications of the client. For more information, see [Command-line options](https://en.oceanbase.com/docs/common-oceanbase-dumper-loader-10000000001417513).

    If you use direct load for import, verify whether the `--parallel` option is specified. The default value of `--parallel` is `1`, which indicates no concurrency. We recommend that you specify the level of concurrency based on the CPU capacity of the tenant.

- Increase the Java virtual machine (JVM) memory

    Insufficient JVM memory will compromise the import performance of obloader. By default, the maximum heap memory of JVM is 4 GB. We recommend that you set the JVM memory to 60% of the available memory of the client. Use an editor to go to the `/bin/obloader` directory under the root directory of obloader. Search for the keywords `-Xms` and `-Xmx`. The former represents the initial heap memory of JVM and the later represents the maximum available heap memory of JVM.

- Improve the transaction processing capacity

    Frequent minor compactions usually cause the transaction processing performance to deteriorate. You can specify the system parameter `freeze_trigger_percentage` to increase the threshold that triggers minor compactions, thereby reducing the minor compaction frequency.

    <main id="notice" type='notice'>
    <h4>Notice</h4>
    <p>Modifying system parameters or other O&M parameters in a production environment is a risky operation. Contact the database administrator (DBA) for confirmation before you perform such operations.
    </p>
    </main>

Empirical values of obloader parameters are listed as follows:

```text
--batch       The default value is 200. Do not set the parameter to a large value.
--thread      The default value is twice the number of logical CPU cores. We recommend that you use the default value.
--rw          The ratio of parsing threads to write threads. The default value is 0.2. The number of parsing threads is the value of --thread x 0.2.
```

Empirical values of OceanBase cluster parameters are listed as follows:

```text
-- Required system variables and parameters
set global max_allowed_packet=1073741824; -- Set it to 1GB.
set global ob_sql_work_area_percentage=30; -- Default value: 5
alter system set freeze_trigger_percentage=30; -- Default value: 70

-- Optional system variables and parameters
alter system set enable_syslog_recycle='True'; -- Default value: false
alter system set max_syslog_file_count=100; -- Default value: 0
alter system set minor_freeze_times=500; -- Default value: 5
alter system set minor_compact_trigger=5; -- Default value: 5
alter system set merge_thread_count=45; -- Default value: 0
alter system set minor_merge_concurrency=20; -- Default value: 0
alter system set writting_throttling_trigger_percentage=85; -- Default value: 10
alter system set flush_log_at_trx_commit=0;  -- Default value: 1
alter system set syslog_io_bandwidth_limit=100;  -- Default value: 30MB
```

<main id="notice" type='explain'>
<h4>Note</h4>
<p>After the data import is completed, restore the system variables and parameters to their default settings.
</p>
</main>

## Example

This section takes a TPC-H table named `LINEITEM` as an example and describes how to import data from the table to OceanBase Database.

1. Prepare the environment.

    Create a business tenant with 4 CPU cores and 7 GB of memory. Set the percentage of memory available for MemTables to 50%, the memory usage that triggers minor compactions to 70%, and the memory usage that triggers write throttling to 90%.

2. Prepare data.

    To import data from `LINEITEM`, the largest table in TPC-H, set the data scale to `4` and the number of data records to `23996604`. The data file information is as follows:

    ```shell
    ls -lrth /data/1/tpch/s4/bak/LINEITEM.*
    -rwxr-xr-x 1 admin admin 325M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.1.csv
    -rwxr-xr-x 1 admin admin 326M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.2.csv
    -rwxr-xr-x 1 admin admin 326M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.3.csv
    -rwxr-xr-x 1 admin admin 327M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.4.csv
    -rwxr-xr-x 1 admin admin 328M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.5.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.6.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.7.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.8.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.9.csv
    ```

3. Import the data to OceanBase Database.

    Run the following command to import the data to OceanBase Database:

    Direct load mode:

    ```shell
    bin/obloader -h xx.x.x.xx -P 2883 -u TPCH@oboracle#OB4216 -p -D TPCH --table LINEITEM --external-data --csv -f /data/1/tpch/s4/bak/   --truncate-table --column-separator='|' --thread 16 --rpc-port=2885 --direct --parallel=16
    ```

    In direct load mode, you connect to an SQL port (2881 by default) instead of an remote procedure call (RPC) port (2882 by default) of the OBServer node. If obloader connects to the OBServer node directly instead of using OceanBase Database Proxy (ODP), you can specify another RPC port for direct load. The RPC port for ODP V4.3.0 is 2885. However, we recommend that you do not get around ODP in a production environment, because the location of the leader of business data is transparent to the client. The client does not need to know the OBServer node where the data resides, and ODP is responsible for SQL routing. When you directly connect to an OBServer node to write data in direct load mode, a transaction that spans across servers is produced if the leader does not reside on this OBServer node.

    Other modes:

    ```shell
    bin/obloader -h xx.x.x.xx -P 2883 -u TPCH@oboracle#OB4216 -p -D TPCH --table LINEITEM --external-data --csv -f /data/1/tpch/s4/bak/   --truncate-table --column-separator='|' --thread 16 
    ```

    The preceding command imports all supported CSV data files in the `/data/1/tpch/s4/bak/` directory to the `LINEITEM` table. If the size of data files to be imported is of the TB level or above, we recommend that you use direct load to improve the import efficiency. Direct load in combination with higher tenant resource specifications can achieve even higher import efficiency.

    For more information, see [Direct load](https://en.oceanbase.com/docs/common-oceanbase-dumper-loader-10000000001417512).
