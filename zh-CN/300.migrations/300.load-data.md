# 数据文件导入 OceanBase 最佳实践

本文介绍如何从数据库导出文件，并将文件导入 OceanBase。 本文将首先介绍常规的导入方法，然后提供性能优化方法供参考，最后给出文件导入的实践案例。

## 从数据库中导出文件

使用以下方式从数据库中导出文件：

1. 数据库自带的工具
2. 第三方工具。DBeaver、SQLyog 和 Navicat 等数据库管理工具都支持导出数据到 CSV、Excel 和 SQL 脚本等格式的数据文件。
3. 编写程序导出

如果您希望从 Oracle 中导出数据文件，您可以使用 Navicat 或 SQL Developer 等数据库开发工具，或仅使用 SQLPlus。

如果您希望从 MySQL 中导出数据文件，您可以使用 Navicat 或 DBeaver 等数据库开发工具，或使用 mysqldump 导出工具。
如果您希望从 OceanBase 数据库中导出数据文件，您可以使用 OBDUMPER。

不要使用太大的文件，例如 100 GB 或更大的数据文件。如果您使用的导数工具无法按照文件块导出，使用切分工具对大文件进行切分。更多信息，参考 [准备数据](https://www.oceanbase.com/docs/common-oceanbase-dumper-loader-1000000001253770)。

## 将数据导入到 OceanBase 数据库

使用以下命令，用 OBLOADER 将数据导入到 OceanBase 数据库：

```bash
$./obloader -h xx.x.x.x -P 2883 -u test@mysql#cluster_a -p ****** -D USERA --csv --table <table_name> --file-regular-expression '.*.csv' /output
```

更多信息，参考 [导入数据](https://www.oceanbase.com/docs/common-oceanbase-dumper-loader-1000000001189500)。

## 性能调优

从导数工具和 OceanBase 数据库两个角度进行性能调优。从以下角度优化导入性能：

- 提高解析性能

    OBLOADER 无法切分二进制格式的文件（ORC 与 Parquet），因此无法利用并发来提高整体的解析性能。您可以考虑手动将大文件拆分成若干小文件，从而提高解析性能。

- 提高并发

    使用 `--thread` 和 `--rw` 提高并发，即提高同时处理的文件数量。若 CPU 占用率始终较高，则说明是机器的 CPU 处理能力已经达到瓶颈，您可以考虑升高客户端机器的规格。更多信息，参考 [命令行选项](https://www.oceanbase.com/docs/common-oceanbase-dumper-loader-1000000001189500)。

    如果您使用的是旁路导入，确认是否指定了 `--parallel`。`--parallel` 默认值为 `1`，也即无并发。建议您根据租户的 CPU 规格指定并发度。

- 提高 JVM 内存

    JVM 内存会影响 OBLOADER 的导入性能。默认的 JVM 最大堆内存是 4G，推荐 JVM 内存为客户端机器可用内存的 60%。通过编辑器打开 `<工具根目录>/bin/obloader`，查找关键字 `-Xms` 与 `-Xmx`，前者代表 JVM 初始化堆内存，后者代表 JVM 最大可申请的堆内存。

- 提升事务处理能力

    频繁的转储是常见的事务处理性能下降原因。您可以通过设置系统参数 `freeze_trigger_percentage` 提高转储阈值，从而降低转储频率。

    <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>在生产环境更改系统参数或其他运维参数属于风险操作，操作前请先咨询 DBA。
    </p>
    </main>

OBLOADER 参数经验值：

```text
--batch       该选项的参数值不宜设置太大，默认 200。
--thread      建议该选项的参数值等于 2 倍的逻辑核心数，默认 2*CPU。
--rw          解析线程与写入线程的比例。解析线程的数量等于 --thread * 0.2，默认 0.2。
```

OceanBase 集群参数经验值：

```text
-- 必设的系统变量和参数
set global max_allowed_packet=1073741824; -- 设置为 1GB
set global ob_sql_work_area_percentage=30; -- 默认值：5
alter system set freeze_trigger_percentage=30; -- 默认值：70

-- 选设的系统变量和参数
alter system set enable_syslog_recycle='True'; -- 默认值：false
alter system set max_syslog_file_count=100; -- 默认值：0
alter system set minor_freeze_times=500; -- 默认值：5
alter system set minor_compact_trigger=5; -- 默认值：5
alter system set merge_thread_count=45; -- 默认值：0
alter system set minor_merge_concurrency=20; -- 默认值：0
alter system set writting_throttling_trigger_percentage=85; -- 默认值：10
alter system set flush_log_at_trx_commit=0;  -- 默认值：1
alter system set syslog_io_bandwidth_limit=100;  -- 默认值：30MB
```

<main id="notice" type='explain'>
<h4>说明</h4>
<p>在数据导入后，将系统变量和参数务重新修改为默认值。
</p>
</main>

## 实践案例

本节将以导入 TPC-H 的表 LINEITEM 为例，介绍如何导入数据至 OceanBase 数据库。

1. 环境介绍。

    业务租户为 4C7G ，MEMTABLE 内存比例 50%，转储参数比例 70%，写限速比例 90%。

2. 准备数据。

    您将导入 TPC-H 中最大的表 LINEITEM。数据规模 `scale` 设置为 `4`。数据记录数为 `23996604`。数据文件信息如下：

    ```shell
    ls -lrth /data/1/tpch/s4/bak/LINEITEM.*
    -rwxr-xr-x 1 admin admin 325M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.1.csv
    -rwxr-xr-x 1 admin admin 326M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.2.csv
    -rwxr-xr-x 1 admin admin 326M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.3.csv
    -rwxr-xr-x 1 admin admin 327M Jul 16 11:48 /data/1/tpch/s4/bak/LINEITEM.4.csv
    -rwxr-xr-x 1 admin admin 328M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.5.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.6.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.7.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.8.csv
    -rwxr-xr-x 1 admin admin 329M Jul 16 11:49 /data/1/tpch/s4/bak/LINEITEM.9.csv
    ```

3. 将数据导入至 OceanBase 数据库。

    使用以下命令，将数据导入至 OceanBase 数据库：

    旁路导入：

    ```shell
    bin/obloader -h xx.x.x.xx -P 2883 -u TPCH@oboracle#OB4216 -p -D TPCH --table LINEITEM --external-data --csv -f /data/1/tpch/s4/bak/   --truncate-table --column-separator='|' --thread 16 --rpc-port=2885 --direct --parallel=16
    ```

    旁路导入不是连接 OBServer 的 SQL 端口（默认 2881）而是连接 RPC 端口（默认 2882）。OBLOADER 如果绕过 ODP 而直连 OBServer，通过额外指定 RPC 端口即可实现旁路导入。ODP V4.3.0 的 RPC 端口是 2885。但是生产中不推荐客户端绕过 ODP。因为原本业务数据的主副本位置对应用客户端是透明的（客户端不需要知道数据在哪个 OBServer 节点上，ODP 会负责 SQL 路由）。直连 OBServer 旁路写入数据，如果主副本不在这个节点，将产生跨机事务。

    非旁路导入：

    ```shell
    bin/obloader -h xx.x.x.xx -P 2883 -u TPCH@oboracle#OB4216 -p -D TPCH --table LINEITEM --external-data --csv -f /data/1/tpch/s4/bak/   --truncate-table --column-separator='|' --thread 16 
    ```

    以上命令均将 `/data/1/tpch/s4/bak/` 目录下所有已支持的 CSV 数据文件导入到表 `LINEITEM` 中。如果您的数据文件大小为 TB 以上，请使用旁路导入提高效率。配合更大的租户资源规格，效率将更高。

    更多信息，参考 [旁路导入](https://www.oceanbase.com/docs/common-oceanbase-dumper-loader-1000000001189498)。
